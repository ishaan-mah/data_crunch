# qwen_bespoke_causal
model_name_or_path: Qwen/Qwen2.5-7B-Instruct
output_dir: /mnt/output/Qwen_bespoke_causal
dataset: qwen_bespoke_causal
template: qwen    # tells LLaMA-Factory to use Qwenâ€™s chat formatting
stage: sft
do_train: true
finetuning_type: full
deepspeed: examples/deepspeed/ds_z2_config.json
# training params
num_train_epochs: 3.0
per_device_train_batch_size: 1
gradient_accumulation_steps: 12   # adjust if fewer GPUs
learning_rate: 1e-5
lr_scheduler_type: cosine
warmup_ratio: 0.1
weight_decay: 0.0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1e-08
logging_steps: 1
save_steps: 275
seed: 42
# hardware
bf16: true
ddp_find_unused_parameters: false
report_to: wandb
run_name: qwen_bespoke_causal